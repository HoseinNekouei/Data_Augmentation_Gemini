{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoseinNekouei/Data_Augmentation_Gemini/blob/main/Gemini_Data_Augmentation_v_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnWMe82eO9LR"
      },
      "source": [
        "## Data Augmentaion via Gemini 1.0 pro\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06sbdCgEV78R",
        "outputId": "c5308fbc-4d34-48ff-a1a8-9dc9816b013b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6PSHJL3ETnkt"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Add Google API key in secret manager\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY_ATENA')\n",
        "\n",
        "# Configure the genai library with the API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "72-MCzL6DE0i"
      },
      "outputs": [],
      "source": [
        "def generate_text(prompt):\n",
        "  \"\"\"\n",
        "  Generates text based on a given prompt using a specified generative model and configuration.\n",
        "\n",
        "  This function initializes a generative model and a generation configuration, then uses the model\n",
        "  to generate content based on the provided prompt. It includes safety settings to allow certain\n",
        "  categories of potentially harmful content.\n",
        "\n",
        "  Args:\n",
        "      prompt (str): The text prompt to generate content from.\n",
        "\n",
        "\n",
        "  Returns:\n",
        "      str: The generated text response from the model.\n",
        "\n",
        "\n",
        "  Note:\n",
        "        generation_config (dict): Configuration settings for text generation, including candidate count,\n",
        "                                maximum output tokens, top_k, and temperature. This parameter is not\n",
        "                                used within the function as the configuration is initialized inside\n",
        "                                the function.\n",
        "\n",
        "  Example:\n",
        "      prompt = \"Once upon a time in a faraway land,\"\n",
        "      response = generate_text(None, prompt, None)\n",
        "      print(response)  # Output the generated text\n",
        "  \"\"\"\n",
        "\n",
        "  model= genai.GenerativeModel('gemini-1.0-pro')\n",
        "\n",
        "  generation_config= genai.types.GenerationConfig(\n",
        "      candidate_count=1,\n",
        "      max_output_tokens=36,\n",
        "      # stop_sequences=['\\n'],\n",
        "      top_k=1,\n",
        "      temperature=1.0\n",
        "  )\n",
        "\n",
        "  response = model.generate_content(\n",
        "    prompt,\n",
        "    safety_settings= {\n",
        "        'HARM_CATEGORY_HARASSMENT': 'BLOCK_NONE',\n",
        "        'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',\n",
        "        'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_NONE',\n",
        "        'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'},\n",
        "    generation_config= generation_config\n",
        "  )\n",
        "\n",
        "  return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVQCe0uKG0yY",
        "outputId": "ac5e9f6c-5fc3-4b0c-fafc-83270013ad60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zufrscqSVVPW"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def load_paraphrized_tweets(dataset_url):\n",
        "    \"\"\"\n",
        "    Loads and processes a dataset of paraphrased tweets from a CSV file.\n",
        "\n",
        "    This function loads the dataset from the provided URL, filters it to include\n",
        "    only relevant columns ('text' and 'airline_sentiment'), and returns the processed dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset_url (str): The URL or file path to the CSV file containing the dataset.\n",
        "\n",
        "    Returns:\n",
        "        DatasetDict: A dictionary-like object containing the loaded and processed dataset.\n",
        "\n",
        "    Example:\n",
        "        dataset_url = '/content/drive/MyDrive/dataset/US_airline/Parapherized_Tweets.csv'\n",
        "        raw_data = load_paraphrized_tweets(dataset_url)\n",
        "        print(raw_data['train'][:3])  # Print the first 3 records in the training set\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the CSV file in memory\n",
        "    raw_data = load_dataset('csv', data_files=dataset_url, sep=',')\n",
        "\n",
        "    # raw_data['train']= raw_data['train'].filter(lambda x: x['airline_sentiment_confidence']>= 0.9 )\n",
        "\n",
        "    # Select only the 'text' and 'airline_sentiment' columns\n",
        "    raw_data['train']= raw_data['train'].select_columns(['text', 'airline_sentiment'])\n",
        "\n",
        "    return raw_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SCDL8KNG-P7u"
      },
      "outputs": [],
      "source": [
        "def get_neutral_tweets(raw_data):\n",
        "    \"\"\"\n",
        "    Filters and returns tweets with neutral sentiment from the given dataset.\n",
        "\n",
        "    This function shuffles the dataset and then extracts tweets that have a neutral sentiment.\n",
        "\n",
        "    Args:\n",
        "        raw_data (DataFrame): The dataset containing tweets. It is expected to have a 'train'\n",
        "                              column that includes a list of tweet dictionaries, and each\n",
        "                              tweet dictionary should have an 'airline_sentiment' key.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each representing a tweet with a neutral sentiment.\n",
        "\n",
        "    Example:\n",
        "        raw_data = {\n",
        "            'train': [\n",
        "                {'airline_sentiment': 'neutral', 'text': 'Flight was okay.'},\n",
        "                {'airline_sentiment': 'positive', 'text': 'Great service!'},\n",
        "                {'airline_sentiment': 'neutral', 'text': 'No issues, decent experience.'},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        neutral_tweets = get_neutral_tweets(raw_data)\n",
        "        for tweet in neutral_tweets[:3]:\n",
        "            print(tweet)\n",
        "    \"\"\"\n",
        "\n",
        "    raw_data['train']= raw_data['train'].shuffle(812)\n",
        "\n",
        "    neutral_tweets= [item for item in raw_data['train'] if item['airline_sentiment']=='neutral']\n",
        "\n",
        "    return neutral_tweets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_positive_tweets(raw_data):\n",
        "    \"\"\"\n",
        "    Filters and returns positive tweets from the given dataset.\n",
        "\n",
        "    This function shuffles the dataset and then extracts tweets that have a positive sentiment.\n",
        "\n",
        "    Args:\n",
        "        raw_data (DataFrame): The dataset containing tweets. It is expected to have a 'train'\n",
        "                              column that includes a list of tweet dictionaries, and each\n",
        "                              tweet dictionary should have an 'airline_sentiment' key.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionaries, each representing a tweet with a positive sentiment.\n",
        "\n",
        "    Example:\n",
        "        raw_data = {\n",
        "            'train': [\n",
        "                {'airline_sentiment': 'positive', 'text': 'Great flight!'},\n",
        "                {'airline_sentiment': 'negative', 'text': 'Terrible service.'},\n",
        "                {'airline_sentiment': 'positive', 'text': 'Loved the experience!'},\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        positive_tweets = get_positive_tweets(raw_data)\n",
        "        for tweet in positive_tweets[:3]:\n",
        "            print(tweet)\n",
        "    \"\"\"\n",
        "\n",
        "    raw_data['train']= raw_data['train'].shuffle(812)\n",
        "\n",
        "    positive_tweets= [item for item in raw_data['train'] if item['airline_sentiment']=='positive']\n",
        "\n",
        "    return positive_tweets\n"
      ],
      "metadata": {
        "id": "-RiPdLmvaA8C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-G8OXL-bj1oE"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def main(tweets, debug=False):\n",
        "  '''\n",
        "  Augment a dataset of neutral tweets by generating new text and saving it to a CSV file.\n",
        "\n",
        "  This function generates new text based on a prompt, appends it to the existing dataset, and\n",
        "  saves the updated dataset to a CSV file at regular intervals. It also introduces a delay\n",
        "  between requests to avoid overloading the generation API.\n",
        "\n",
        "  Parameters:\n",
        "      tweets (list): List of neutral tweets to augment.\n",
        "      debug (bool): Whether to run in debug mode (optional).\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "\n",
        "  Notes:\n",
        "      The function saves the updated dataset to a CSV file at regular intervals (every 10 iterations)\n",
        "      and introduces a 5-second delay between requests to avoid overloading the generation API.\n",
        "  '''\n",
        "\n",
        "  # Iterate over the list of tweets, with index and tweet values\n",
        "  for index, tweet in enumerate(tweets):\n",
        "\n",
        "    # Create a prompt string by concatenating a fixed prefix with the tweet's text\n",
        "    prompt = \"generate text that start by @[airline's name] like: \" + tweet.get('text')\n",
        "\n",
        "    # Extract the airline's sentiment from the tweet\n",
        "    airline_sentiment= tweet.get('airline_sentiment')\n",
        "\n",
        "    # Generate new text based on the prompt and configuration\n",
        "    response = generate_text(prompt)\n",
        "\n",
        "    # Create a dictionary to store the paraphrased text and its sentiment\n",
        "    parapherize_text = {'text': response.text, 'airline_sentiment': airline_sentiment}\n",
        "\n",
        "    # Add the paraphrased text and sentiment to the training dataset\n",
        "    raw_data['train'] = raw_data['train'].add_item(parapherize_text)\n",
        "\n",
        "    # Print a message indicating that the paraphrased text has been added to the dataset\n",
        "    print(f'[Tweet {(index + 1)}]: {airline_sentiment}; added.')\n",
        "\n",
        "    if debug:\n",
        "\n",
        "      print(f'[prompt]: {prompt} ->  ({airline_sentiment})')\n",
        "\n",
        "      # Print the paraphrased text, with the last generated text and its corresponding sentiment\n",
        "      print(f\"[parapherized_text]: {raw_data['train']['text'][-1]}-> ({raw_data['train']['airline_sentiment'][-1]})\")\n",
        "\n",
        "      print('------')\n",
        "\n",
        "\n",
        "    # Check if the current iteration is a multiple of 10\n",
        "    if (index + 1) % 10 == 0:\n",
        "\n",
        "      # Save the updated dataset to a CSV file\n",
        "      raw_data['train'].to_csv('/content/drive/MyDrive/dataset/US_airline/Parapherized_Tweets.csv')\n",
        "\n",
        "      # Clear the output to display the updated message\n",
        "      clear_output()\n",
        "\n",
        "      print(f'Dataset was updated in index: {(index + 1)}')\n",
        "\n",
        "    # Introduce a 5-second delay between requests to avoid overloading the generation API\n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y4sPSUn2k7fP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "\n",
        "def results(orginal_dataset_url):\n",
        "  \"\"\"\n",
        "  Load and visualize the original and augmented datasets.\n",
        "\n",
        "  This function loads the original dataset from a CSV file, filters it to only include\n",
        "  tweets with a sentiment confidence of at least 0.9, and then visualizes the\n",
        "  original and augmented datasets using bar charts.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  original_dataset = load_dataset('csv', data_files= orginal_dataset_url)\n",
        "  original_dataset['train']= original_dataset['train'].filter(lambda x: x['airline_sentiment_confidence']>= 0.9 )\n",
        "\n",
        "\n",
        "  # train_labels = dataset.set_format('pandas')\n",
        "  df_original_dataset= original_dataset['train'].to_pandas()\n",
        "\n",
        "  df_augmented_dataset= raw_data['train'].to_pandas()\n",
        "\n",
        "  print(f'df_original_dataset: {len(df_original_dataset)}')\n",
        "\n",
        "  print(f'df_augmented_dataset: {len(df_augmented_dataset)}')\n",
        "\n",
        "  df_original = df_original_dataset['airline_sentiment'].value_counts()\n",
        "\n",
        "  df_augmented = df_augmented_dataset['airline_sentiment'].value_counts()\n",
        "\n",
        "  print('')\n",
        "  print(df_original)\n",
        "  print(df_augmented)\n",
        "\n",
        "  # Plot the bar chart for train and test label distributions\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.bar(df_original.index, df_original.values, color= 'green')\n",
        "  plt.title('Original dataset')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.bar(df_augmented.index, df_augmented.values, color='blue')\n",
        "  plt.title('Augmented dataset')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvAuHBPAYZk1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "33f44501fbe14ea99e012a217206d5b3",
            "e309018fec7e470b84f4c3788b8e5956",
            "1fa57eb4fd0449a0a9d4eeeb053e441e",
            "da4290fec6954fb2ada1640ede10b648",
            "b40b4c5b355a4bd0909b574b05fcbdd6",
            "fcd0f87a1f9b4ce9b8b0f0d5f2e2a3f7",
            "1c909c9ef99441b89535f3e8d361e88e",
            "efa4c127b6d94accaba0025c14895e23",
            "40053c4e05b543c89ee1d80ab99827b0",
            "6872c55e23a545ca8528e278d095b98a",
            "66fcab304adf45f78bffae2e20de7080",
            "bd8c6b6a09fc4c29bf7cb9f6b16847b4"
          ]
        },
        "outputId": "94b3abda-7c43-40fa-abfb-8f46a1919079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset was updated in index: 10\n",
            "[Tweet 11]: positive; added.\n",
            "[Tweet 12]: positive; added.\n",
            "[Tweet 13]: positive; added.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This script processes a dataset of tweets about US airlines. It loads the dataset,\n",
        "filters tweets based on sentiment, and performs further analysis on the positive tweets.\n",
        "\n",
        "Usage:\n",
        "    Run the script directly to execute the main processing and analysis pipeline.\n",
        "\n",
        "Variables:\n",
        "    raw_dataset_url (str): The file path to the paraphrased tweets dataset.\n",
        "    raw_data (DataFrame): The loaded dataset containing paraphrased tweets.\n",
        "    neutral_tweets (DataFrame): The subset of tweets with a neutral sentiment.\n",
        "    positive_tweets (DataFrame): The subset of tweets with a positive sentiment.\n",
        "    original_dataset_url (str): The file path to the original tweets dataset.\n",
        "\n",
        "Functions:\n",
        "    load_paraphrized_tweets(url): Loads the dataset from the given URL and returns it as a DataFrame.\n",
        "    get_neutral_tweets(data): Filters and returns the neutral tweets from the dataset.\n",
        "    get_positive_tweets(data): Filters and returns the positive tweets from the dataset.\n",
        "    results(url): Performs some analysis or processing on the dataset at the given URL.\n",
        "    main(tweets): The main function that processes the positive tweets.\n",
        "\n",
        "Exceptions:\n",
        "    If an error occurs in the main function, it is caught and printed to the console.\n",
        "\n",
        "Example:\n",
        "    To run the script, simply execute it in a Python environment:\n",
        "\n",
        "    $ python script_name.py\n",
        "\n",
        "Note:\n",
        "    Make sure that the dataset files are available at the specified paths before running the script.\n",
        "\"\"\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  raw_dataset_url= '/content/drive/MyDrive/dataset/US_airline/Parapherized_Tweets.csv'\n",
        "\n",
        "  raw_data = load_paraphrized_tweets(raw_dataset_url)\n",
        "\n",
        "  neutral_tweets= get_neutral_tweets(raw_data)\n",
        "\n",
        "  positive_tweets = get_positive_tweets(raw_data)\n",
        "\n",
        "  try:\n",
        "    main(tweets= positive_tweets)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "  orginal_dataset_url='/content/drive/MyDrive/dataset/US_airline/Tweets.csv'\n",
        "\n",
        "  results(orginal_dataset_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMBI+nqARSKhc6hdITwOlTy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33f44501fbe14ea99e012a217206d5b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e309018fec7e470b84f4c3788b8e5956",
              "IPY_MODEL_1fa57eb4fd0449a0a9d4eeeb053e441e",
              "IPY_MODEL_da4290fec6954fb2ada1640ede10b648"
            ],
            "layout": "IPY_MODEL_b40b4c5b355a4bd0909b574b05fcbdd6"
          }
        },
        "e309018fec7e470b84f4c3788b8e5956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd0f87a1f9b4ce9b8b0f0d5f2e2a3f7",
            "placeholder": "​",
            "style": "IPY_MODEL_1c909c9ef99441b89535f3e8d361e88e",
            "value": "Generating train split: "
          }
        },
        "1fa57eb4fd0449a0a9d4eeeb053e441e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efa4c127b6d94accaba0025c14895e23",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40053c4e05b543c89ee1d80ab99827b0",
            "value": 1
          }
        },
        "da4290fec6954fb2ada1640ede10b648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6872c55e23a545ca8528e278d095b98a",
            "placeholder": "​",
            "style": "IPY_MODEL_66fcab304adf45f78bffae2e20de7080",
            "value": " 12432/0 [00:00&lt;00:00, 12806.90 examples/s]"
          }
        },
        "b40b4c5b355a4bd0909b574b05fcbdd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd0f87a1f9b4ce9b8b0f0d5f2e2a3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c909c9ef99441b89535f3e8d361e88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efa4c127b6d94accaba0025c14895e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "40053c4e05b543c89ee1d80ab99827b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6872c55e23a545ca8528e278d095b98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66fcab304adf45f78bffae2e20de7080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd8c6b6a09fc4c29bf7cb9f6b16847b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6cd40ba85a24b67bdccb9ae47bf4b80",
              "IPY_MODEL_c3c2818987e643d586718c9d5a9cf7a2",
              "IPY_MODEL_da629cc1883949ceb2f80b3bb5ce203e"
            ],
            "layout": "IPY_MODEL_29ec6f39cd324db0b30fdbc162b4368b"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}